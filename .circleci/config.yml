version: 2.1

executors:
  docker:
    docker:
      - image: circleci/golang:1.9

jobs:
  build:
    docker:
      - image: circleci/openjdk:8-jdk
    working_directory: ~/repo
    environment:
      MAVEN_OPTS: -Xmx3200m
    steps:
      - checkout
      - restore_cache:
          key: v1-gradle-wrapper-{{ checksum "gradle/wrapper/gradle-wrapper.properties" }}
      - restore_cache:
          key: v1-gradle-cache-{{ checksum "build.gradle" }}
      - run: ./gradlew clean build
      - run: ./gradlew -b build-11.gradle --build-cache assemble
      - run: ./gradlew -b build-cxod.gradle --build-cache assemble
      - run: ./gradlew -q getVersion > build/libs/version.txt
      - save_cache:
          paths:
            - ~/.gradle/wrapper
          key: v1-gradle-wrapper-{{ checksum "gradle/wrapper/gradle-wrapper.properties" }}
      - save_cache:
          paths:
            - ~/.gradle/caches
          key: v1-gradle-cache-{{ checksum "build.gradle" }}
      - store_artifacts:
          path: build/libs
      - persist_to_workspace:
          root: .
          paths:
            - build/libs/*
            - Dockerfile
      - run:
          name: Save test results
          command: |
            mkdir -p ~/test-results/junit/
            find . -type f -regex ".*/build/test-results/.*xml" -exec cp {} ~/test-results/junit/ \;
          when: always
      - store_test_results:
          path: ~/test-results
      - store_artifacts:
          path: ~/test-results/junit

  sonar:
    machine:
      image: ubuntu-1604:201903-01
    steps:
      - checkout
      - run:
          name: Compile
          command: ./gradlew clean compileJava compileTestJava
      - sonarcloud/scan:
          cache_version: 2
      - run:
          name: Check Quality Gate
          command: |
                    REPORT_PATH="/home/circleci/project/.scannerwork/report-task.txt"
                    CE_TASK_ID_KEY="ceTaskId="
                    SONAR_INSTANCE="https://sonarcloud.io"
                    SLEEP_TIME=5
                    # get the compute engine task id
                    ce_task_id=$(cat $REPORT_PATH | grep $CE_TASK_ID_KEY | cut -d'=' -f2)
                    echo "Using task id of ${ce_task_id}"
                    if [ -z "$ce_task_id" ]; then
                       echo "No task id found"
                       exit 1
                    fi
                    # grab the status of the task
                    # if CANCELLED or FAILED, fail the Build
                    # if SUCCESS, stop waiting and grab the analysisId
                    wait_for_success=true
                    while [ "${wait_for_success}" = "true" ]
                    do
                      ce_status=$(curl -s -u "${SONAR_TOKEN}": "${SONAR_INSTANCE}"/api/ce/task?id=${ce_task_id} | jq -r .task.status)
                      echo "Status of SonarQube task is ${ce_status}"
                      if [ "${ce_status}" = "CANCELLED" ]; then
                        echo "SonarQube Compute job has been cancelled - exiting with error"
                        exit 504
                      fi
                      if [ "${ce_status}" = "FAILED" ]; then
                        echo "SonarQube Compute job has failed - exit with error"
                        exit 500
                      fi
                      if [ "${ce_status}" = "SUCCESS" ]; then
                        wait_for_success=false
                      fi
                      sleep "${SLEEP_TIME}"
                    done
                    ce_analysis_id=$(curl -s -u "${SONAR_TOKEN}": "${SONAR_INSTANCE}"/api/ce/task?id=$ce_task_id | jq -r .task.analysisId)
                    echo "Using analysis id of ${ce_analysis_id}"
                    # get the status of the quality gate for this analysisId
                    qg_status=$(curl -s -u "${SONAR_TOKEN}": "${SONAR_INSTANCE}"/api/qualitygates/project_status?analysisId="${ce_analysis_id}" | jq -r .projectStatus.status)
                    echo "Quality Gate status is ${qg_status}"
                    if [ "${qg_status}" != "OK" ]; then
                      echo "Quality gate is not OK - exiting with error"
                      exit 1
                    fi

  docker-build:
    executor: docker
    steps:
      - setup_remote_docker
      - attach_workspace:
          at: .
      - deploy:
          name: Docker Build
          command: |
            VERSION=$(cat ./build/libs/version.txt)
            SHA1_SHORT=${CIRCLE_SHA1::7}
            docker login -u ${DOCKER_USER} -p ${DOCKER_PASSWORD} docker.io
            docker build --target java8 \
              -t ${DOCKER_REPO}:${SHA1_SHORT} \
              -t ${DOCKER_REPO}:${VERSION}-8 \
              -t ${DOCKER_REPO}:${VERSION} \
              -t ${DOCKER_REPO} \
              .
            docker build --target java11 \
              -t ${DOCKER_REPO}:${VERSION}-11 \
              .
            docker build --target cxod8 \
              -t ${DOCKER_REPO}:${VERSION}-CXOD8 \
              .
            docker push ${DOCKER_REPO}:${SHA1_SHORT}
      - run:
          name: Archive Docker images
          command: |
            VERSION=$(cat ./build/libs/version.txt)
            docker save -o image-11.tar ${DOCKER_REPO}:${VERSION}-11
            docker save -o image-8.tar ${DOCKER_REPO}:${VERSION}-8
            docker save -o image-cxod8.tar ${DOCKER_REPO}:${VERSION}-CXOD8
            docker save -o image.tar ${DOCKER_REPO}:${VERSION}
            docker save -o latest.tar ${DOCKER_REPO}:latest
      - persist_to_workspace:
          root: .
          paths:
            - ./image-11.tar
            - ./image-8.tar
            - ./image-cxod8.tar
            - ./image.tar
            - ./latest.tar

  deploy-cxflow:
    executor: aws-eks/python3
    parameters:
      cluster-name:
        description: |
          Name of the EKS cluster.
        type: string
      chart:
        description: |
          Specify for installation a chart reference.
        type: string
      namespace:
        default: 'default'
        description: |
          The kubernetes namespace that should be used.
        type: string
      release-name:
        default: ''
        description: |
          Specify a name for the release.
        type: string
      version:
        default: v3.1.1
        description: the helm client version to install
        type: string
    steps:
      - checkout
      - aws-eks/update-kubeconfig-with-authenticator:
          cluster-name: << parameters.cluster-name >>
          install-kubectl: true
      - run:
          name: Create namespace
          command: |
            export NAMESPACE_EXISTS=$(kubectl get namespaces | grep << parameters.namespace >>)
            if [[ ${NAMESPACE_EXISTS} ]]; then echo "Namespace already exists"; else kubectl create namespace << parameters.namespace >>; fi
      - run:
          name: Change appVersion
          command: |
            sed -i "s/appVersion:[[:space:]]*.*/appVersion: '${CIRCLE_SHA1::7}'/g" ./helm/cxflow/Chart.yaml
      - helm/install-helm-client:
          version: << parameters.version >>
      - run:
          name: Install cxflow service on cluster
          command: |
            helm upgrade --install --atomic --namespace << parameters.namespace >> << parameters.release-name >> \
              --set cxflow.checkmarxUsername=${CHECKMARX_USERNAME} \
              --set cxflow.checkmarxPassword=${CHECKMARX_PASSWORD} \
              --set cxflow.checkmarxBaseUrl=${CHECKMARX_BASE_URL} \
              --set cxflow.githubToken=${GITHUB_TOKEN} \
              --set cxflow.githubWebhookToken=${GITHUB_WEBHOOK_TOKEN} \
              --set cxflow.checkmarxClientSecret=${CHECKMARX_CLIENT_SECRET} \
              --set cxflow.jiraUrl=${JIRA_URL} \
              --set cxflow.jiraUserName=${JIRA_USERNAME} \
              --set cxflow.jiraToken=${JIRA_TOKEN} \
              --set cxflow.jiraProject=${JIRA_PROJECT} \
              --set cxflow.azureToken=${AZURE_TOKEN} \
              --set ingress.hosts[0].host=<< parameters.release-name >>.${EXTERNAL_DNS_DOMAIN} \
              --set ingress.hosts[0].paths[0]="/*" \
              << parameters.chart >>
      - run:
          name: Show running pods
          command: |
            sleep 60
            kubectl get pods -n << parameters.namespace >>

  component-tests:
    docker:
      - image: "circleci/openjdk:8-jdk"
    steps:
      - checkout
      - run:
          name: Run Component Tests
          command: ./gradlew clean componentTest --info
      - run:
          name: Save test results
          command: |
            mkdir -p ~/test-results/junit/
            find . -type f -regex ".*/build/test-results/.*xml" -exec cp {} ~/test-results/junit/ \;
          when: always
      - store_test_results:
          path: ~/test-results
      - store_artifacts:
          path: ~/test-results/junit

  e2e-tests:
    docker:
      - image: "circleci/openjdk:8-jdk"
    steps:
      - checkout
      - run:
          name: Run E2E Tests
          command: |
            export GITHUB_HOOK_TARGET=https://cxflow-${CIRCLE_SHA1::7}.${EXTERNAL_DNS_DOMAIN}
            export ADO_HOOK_TARGET=https://cxflow-${CIRCLE_SHA1::7}.${EXTERNAL_DNS_DOMAIN}
            ./gradlew clean e2eTests --info -DGITHUB_target=${GITHUB_HOOK_TARGET} -DGITHUB_repo=${GITHUB_HOOK_REPO} -DGITHUB_namespace=${GITHUB_HOOK_NAMESPACE} -DADO_target=${ADO_HOOK_TARGET} -DADO_repo=${ADO_HOOK_REPO}-DADO_namespace=${ADO_HOOK_NAMESPACE}
      - run:
          name: Save test results
          command: |
            mkdir -p ~/test-results/junit/
            find . -type f -regex ".*/build/test-results/.*xml" -exec cp {} ~/test-results/junit/ \;
          when: always
      - store_test_results:
          path: ~/test-results
      - store_artifacts:
          path: ~/test-results/junit

  integration-tests:
    docker:
      - image: "circleci/openjdk:8-jdk"
    steps:
      - checkout
      - run:
          name: Run Integration Tests
          command: |
            export HOOK_TARGET=https://cxflow-${CIRCLE_SHA1::7}.${EXTERNAL_DNS_DOMAIN}
            ./gradlew clean integrationTest --info -Dtarget=${HOOK_TARGET} -Drepo=${HOOK_REPO} -Dnamespace=${HOOK_NAMESPACE}
      - run:
          name: Save test results
          command: |
            mkdir -p ~/test-results/junit/
            find . -type f -regex ".*/build/test-results/.*xml" -exec cp {} ~/test-results/junit/ \;
          when: always
      - store_test_results:
          path: ~/test-results
      - store_artifacts:
          path: ~/test-results/junit

  cleanup:
    executor: aws-eks/python3
    parameters:
      cluster-name:
        type: string
      namespace:
        type: string
      release-name:
        type: string
      version:
        type: string
    steps:
      - aws-eks/update-kubeconfig-with-authenticator:
          cluster-name: << parameters.cluster-name >>
          install-kubectl: true
      - helm/install-helm-client:
          version: << parameters.version >>
      - run:
          name: Save application logs
          command: |
            export POD_NAME=$(kubectl get pods -o custom-columns=:metadata.name -n << parameters.namespace >> | grep -v ingress | grep -v external-dns | tr -d '\n')
            mkdir -p ~/application-logs/
            kubectl logs ${POD_NAME} -n << parameters.namespace >> > ~/application-logs/${POD_NAME}.log
      - run:
          name: Delete cxflow deployment
          command: helm uninstall << parameters.release-name >> --namespace << parameters.namespace >>
      - run:
          name: Delete namespace
          command: kubectl delete namespace << parameters.namespace >>
      - store_artifacts:
          path: ~/application-logs

  docker-push-stable:
    executor: docker
    steps:
      - attach_workspace:
          at: /tmp/workspace
      - setup_remote_docker
      - run:
          name: Load archived Docker images
          command: |
            docker load -i /tmp/workspace/image-11.tar
            docker load -i /tmp/workspace/image-8.tar
            docker load -i /tmp/workspace/image.tar
            docker load -i /tmp/workspace/latest.tar
      - run:
          name: Publish Docker images to Docker Hub
          command: |
            docker login -u ${DOCKER_USER} -p ${DOCKER_PASSWORD} docker.io
            docker push ${DOCKER_REPO}

  publish-github-release:
    docker:
      - image: circleci/golang:1.9
    steps:
      - attach_workspace:
          at: .
      - run:
          name: "Publish Release on GitHub"
          command: |
            go get github.com/tcnksm/ghr
            VERSION=$(cat ./build/libs/version.txt)
            rm ./build/libs/version.txt
            ghr -t ${GITHUB_TOKEN} -u ${CIRCLE_PROJECT_USERNAME} -n ${VERSION} -r ${CIRCLE_PROJECT_REPONAME} -c ${CIRCLE_SHA1} -delete ${VERSION} ./build/libs/

orbs:
  sonarcloud: sonarsource/sonarcloud@1.0.1
  aws-eks: circleci/aws-eks@0.2.6
  kubernetes: circleci/kubernetes@0.4.0
  helm: circleci/helm@0.2.3

workflows:
  version: 2
  sonar:
    jobs:
      - sonar:
          context: sonarcloud
          filters:
            branches:
              only:
                - develop
                - /pr-.*/
                - /pr .*/
                - sonar
  build_deploy:
    jobs:
      - build
      - docker-build:
          requires:
            - build
          filters:
            branches:
              only: 
                - develop
                - /pr-.*/
                - /pr .*/
      - component-tests:
          requires:
            - build
      - deploy-cxflow:
          cluster-name: eks-cxflow-ci
          chart: ./helm/cxflow
          namespace: cxflow-${CIRCLE_SHA1::7}
          release-name: cxflow-${CIRCLE_SHA1::7}
          version: v3.1.1
          filters:
            branches:
              only: 
                - develop
                - /pr-.*/
                - /pr .*/
          requires:
            - docker-build
            - component-tests
      - e2e-tests:
          filters:
            branches:
              only: 
                - develop
                - /pr-.*/
                - /pr .*/
          requires:
            - deploy-cxflow
      - integration-tests:
          requires:
            - deploy-cxflow
      - docker-push-stable:
          filters:
            branches:
              only: develop
          requires:
            - e2e-tests
            - integration-tests
      - publish-github-release:
          filters:
            branches:
              only: develop
          requires:
            - e2e-tests
            - integration-tests
      - cleanup:
          cluster-name: eks-cxflow-ci
          namespace: cxflow-${CIRCLE_SHA1::7}
          release-name: cxflow-${CIRCLE_SHA1::7}
          version: v3.1.1
          filters:
            branches:
              only: 
                - develop
                - /pr-.*/
                - /pr .*/
          requires:
            - e2e-tests
            - integration-tests
